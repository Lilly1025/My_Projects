{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "O6tTY5EctIhI"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lilly1025/My_Projects/blob/main/%E0%B8%AA%E0%B8%B3%E0%B9%80%E0%B8%99%E0%B8%B2%E0%B8%82%E0%B8%AD%E0%B8%87_holybasilVSsweet_basil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone DATASET"
      ],
      "metadata": {
        "id": "iEBv7R0zRSCb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSWfhLmo83Mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/TAUTOLOGY-EDUCATION/DATASET/"
      ],
      "metadata": {
        "id": "4T8015XnRWNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8259e8-91c5-40da-8e32-2db3ef04775d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DATASET'...\n",
            "remote: Enumerating objects: 1301, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 1301 (delta 4), reused 12 (delta 3), pack-reused 1285\u001b[K\n",
            "Receiving objects: 100% (1301/1301), 1.96 GiB | 33.58 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Filtering content: 100% (3/3), 5.02 GiB | 56.57 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip"
      ],
      "metadata": {
        "id": "O6tTY5EctIhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/DATASET/HorapaVsKaprao/horapa-01.zip\" -d \"/content/DATASET/HorapaVsKaprao\""
      ],
      "metadata": {
        "id": "RpJryJzctJHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/DATASET/HorapaVsKaprao/horapa-02.zip\" -d \"/content/DATASET/HorapaVsKaprao\""
      ],
      "metadata": {
        "id": "Y1CvkZmo9ipC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/DATASET/HorapaVsKaprao/kaprao.zip\" -d \"/content/DATASET/HorapaVsKaprao\""
      ],
      "metadata": {
        "id": "tGer4lly9d2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Module\n"
      ],
      "metadata": {
        "id": "H2BezXGGiqoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Zy3z11vWidVs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "PdvCc_GFlDPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define constant"
      ],
      "metadata": {
        "id": "qLR-u4LHlssR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "INIT_LR  = 1e-3\n",
        "BS = 32\n",
        "\n",
        "width = 256\n",
        "height = 256\n",
        "\n",
        "default_image_size = tuple((width, height))\n",
        "depth = 3\n",
        "\n",
        "directory_root = './DATASET/HorapaVsKaprao/'"
      ],
      "metadata": {
        "id": "naHt5sfKlD7S"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Image to Array with resizing to square"
      ],
      "metadata": {
        "id": "UdpJndJflyCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            height, width, channels = image.shape\n",
        "\n",
        "            if height > width:\n",
        "                image = image[height//2 - width//2:height//2 + width//2, 0:width]\n",
        "            else:\n",
        "                image = image[0:height, width//2 - height//2:width//2 + height//2]\n",
        "\n",
        "            image = cv2.resize(image, default_image_size)\n",
        "\n",
        "            return img_to_array(image)\n",
        "        else:\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "cdvUxApxlIjY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load image to our code"
      ],
      "metadata": {
        "id": "9Vue1axrnZSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_list, label_list = [], []\n",
        "\n",
        "try:\n",
        "    print(\"[INFO] Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "\n",
        "    for plant_name in root_dir :\n",
        "        print(f\"[INFO] Processing {plant_name} ...\")\n",
        "\n",
        "        plant_name_list = listdir(f\"{directory_root}/{plant_name}\")\n",
        "\n",
        "        for image in plant_name_list :\n",
        "            image_path = f\"{directory_root}/{plant_name}/{image}\"\n",
        "            if image_path.endswith(\".jpg\") or image_path.endswith(\".JPG\"):\n",
        "                image_list.append(convert_image_to_array(image_path))\n",
        "                label_list.append(plant_name)\n",
        "        print(\"[INFO] Image loading success\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBD9-zBRnYnh",
        "outputId": "9329a4ef-5fe9-48cd-d01a-7809aa59d8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Loading images ...\n",
            "[INFO] Processing .ipynb_checkpoints ...\n",
            "[INFO] Image loading success\n",
            "[INFO] Processing kapao ...\n",
            "[INFO] Image loading success\n",
            "[INFO] Processing horapa ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labeling"
      ],
      "metadata": {
        "id": "8O_uQFo6zMp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "pickle.dump(label_binarizer,open('label_tranform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)\n",
        "\n",
        "print(f\"There are {n_classes} classes which is {', '.join(label_binarizer.classes_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjDXPtG3zIwr",
        "outputId": "c174d029-d188-4795-95a7-14e13b577b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 classes which is horapa, kapao\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing image"
      ],
      "metadata": {
        "id": "lXPe8g8t1Ttr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16)"
      ],
      "metadata": {
        "id": "NwLrRcbx1W-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show sample of dataset"
      ],
      "metadata": {
        "id": "-o0bw_4d1qML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 10))\n",
        "\n",
        "for i in range(6):\n",
        "    if i  % 2 == 0:\n",
        "        ax = plt.subplot(3 , 2, i + 1)\n",
        "        plt.imshow(cv2.cvtColor(image_list[460+i] / 255., cv2.COLOR_BGR2RGB))\n",
        "        plt.title(label_binarizer.classes_[i%2])\n",
        "        plt.axis(\"off\")\n",
        "    else:\n",
        "        ax = plt.subplot(3 , 2, i + 1)\n",
        "        plt.imshow(cv2.cvtColor(image_list[i] / 255., cv2.COLOR_BGR2RGB))\n",
        "        plt.title(label_binarizer.classes_[i%2])\n",
        "        plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "kQIlJ3xx1taa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting data"
      ],
      "metadata": {
        "id": "r6_KJKnB37Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Spliting data to train, validate and test\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 2)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state = 2)\n",
        "\n",
        "print(f\"[INFO] All dataset: {len(image_list)}\")\n",
        "print(f\"[INFO] Training dataset: {len(y_train)}\")\n",
        "print(f\"[INFO] Validation dataset: {len(y_val)}\")\n",
        "print(f\"[INFO] Testing dataset: {len(y_test)}\")\n",
        "print(f\"[INFO] Training dataset: {len(x_train)}\")"
      ],
      "metadata": {
        "id": "_07YDpak397g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1cde17-e029-429e-800b-7f1b90f51653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Spliting data to train, validate and test\n",
            "[INFO] All dataset: 1115\n",
            "[INFO] Training dataset: 713\n",
            "[INFO] Validation dataset: 179\n",
            "[INFO] Testing dataset: 223\n",
            "[INFO] Training dataset: 713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1yzOV3qQtka",
        "outputId": "54ee7ef8-3d5d-46ff-b24a-cb9ddf94ba86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class Weighting"
      ],
      "metadata": {
        "id": "oZRh2qUc6Ci9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"[INFO] Class weighting ...\")\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                            classes=np.unique(np.ravel(y_train, order='C'))\n",
        "                                            ,y=np.ravel(y_train, order='C'))\n",
        "\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "print(class_weight_dict)\n"
      ],
      "metadata": {
        "id": "3pomnne66BXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentator กรณีข้อมูลแบบ imbalanced"
      ],
      "metadata": {
        "id": "91tKrV1y7ZOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")"
      ],
      "metadata": {
        "id": "SqNuLv7z7c3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "image_flow = aug.flow(x_train, y_train, batch_size=BS)\n",
        "\n",
        "for i in range(9):\n",
        "    img, label = image_flow.next()\n",
        "    ax = plt.subplot(3,3,i+1)\n",
        "    plt.imshow(cv2.cvtColor(img[0] / 255., cv2.COLOR_BGR2RGB ))\n",
        "    plt.title(label_binarizer.classes_[label[0]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "nndhQRXkCaI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MAKE MODEL**"
      ],
      "metadata": {
        "id": "VRTJbzNLDtRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Making model...\")\n",
        "inputShape = (height,width,depth)\n",
        "ChanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth,height,width)\n",
        "    ChanDim = 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\", activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "opt = Adam(learning_rate=INIT_LR, beta_1=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1U0DpctDvXT",
        "outputId": "7589993c-99a0-46a6-bccd-09948d640892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Making model...\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_28 (Conv2D)          (None, 256, 256, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPooli  (None, 85, 85, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 85, 85, 32)        0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 85, 85, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 85, 85, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPooli  (None, 42, 42, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 42, 42, 64)        0         \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 42, 42, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 42, 42, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPooli  (None, 21, 21, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 21, 21, 128)       0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 56448)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1024)              57803776  \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58082561 (221.57 MB)\n",
            "Trainable params: 58082561 (221.57 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early Stopping"
      ],
      "metadata": {
        "id": "nO9lTSq-IwGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(\n",
        "                            monitor='val_accuracy',\n",
        "                            verbose=1,\n",
        "                            patience=20,\n",
        "                            mode='max',\n",
        "                            restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "xbd2hEjXFkWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "C4lDj6ZqJQtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Training ...\")\n",
        "\n",
        "history = model.fit(\n",
        "                aug.flow(x_train, y_train, batch_size=BS),\n",
        "                validation_data = (x_val, y_val),\n",
        "                steps_per_epoch=len(x_train) // BS,\n",
        "                epochs=EPOCHS,\n",
        "                verbose=1,\n",
        "                callbacks=[es],\n",
        "                class_weight=class_weight_dict)"
      ],
      "metadata": {
        "id": "4zWFydPQJVjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show training graph accuracy"
      ],
      "metadata": {
        "id": "ombt8qEZKeQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs =  range(1, len(acc)+1)\n",
        "\n",
        "#Train and Validation accuracy\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and Validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JxYo6KQWKk3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "CmqyGzRlL7rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "train_scores = model.evaluate(x_train, y_train)\n",
        "test_scores = model.evaluate(x_test, y_test)\n",
        "all_scores = model.evaluate(np_image_list, image_labels)\n",
        "print(f\"Test Accuracy (on train dataset): {train_scores[1]*100}\")\n",
        "print(f\"Test Accuracy (on test dataset): {test_scores[1]*100}\")\n",
        "print(f\"Test Accuracy (on all dataset): {all_scores[1]*100}\")\n"
      ],
      "metadata": {
        "id": "X3r9ulvcL3Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cm(labels, predictions, p =0.5):\n",
        "    cm = confusion_matrix(labels, prediction > p)\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "    plt.title('confusion matrix')\n",
        "    plt.xlabel('Actual label')\n",
        "    plt.ylabel('Predicted label')\n",
        "\n",
        "    print(f'Actual is \"{label_binarizer.classes_[0]}\" and Prediction is \"{label_binarizer.classes_[0]}\": ',cm[0][0])\n",
        "    print(f'Actual is \"{label_binarizer.classes_[0]}\" and Prediction is \"{label_binarizer.classes_[1]}\": ',cm[0][1])\n",
        "    print(f'Actual is \"{label_binarizer.classes_[1]}\" and Prediction is \"{label_binarizer.classes_[0]}\": ',cm[1][0])\n",
        "    print(f'Actual is \"{label_binarizer.classes_[1]}\" and Prediction is \"{label_binarizer.classes_[1]}\": ',cm[1][1])\n",
        "\n",
        "test_predictions_baseline = model.predict(x_test, batch_size=BS)\n",
        "\n",
        "plot_cm(y_test, test_predictions_baseline)"
      ],
      "metadata": {
        "id": "19wjK1J_M0FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model to disk\n",
        "print(\"[INFO] Saving model ...\")\n",
        "model.save('save_model/model.h5')"
      ],
      "metadata": {
        "id": "rdHEJEz_O510"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}